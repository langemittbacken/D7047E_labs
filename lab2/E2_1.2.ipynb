{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "data = torchvision.datasets.MNIST(\"./\", train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = torchvision.datasets.MNIST(\"./\", train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9*len(data))\n",
    "test_size = len(data) - train_size\n",
    "train_set, val_set = torch.utils.data.random_split(data, [train_size,test_size])\n",
    "\n",
    "BATCH_SIZE = 1000\n",
    "SHUFFLE = True\n",
    "LEARNING_RATE = 0.001  \n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size= BATCH_SIZE, shuffle= SHUFFLE )\n",
    "test_loader = DataLoader(test_data, batch_size= BATCH_SIZE, shuffle= SHUFFLE)\n",
    "val_loader = DataLoader(val_set, batch_size= BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [54/54] - Loss: 1.8351564407348633  0.7475 Val Acc\n",
      "best model here\n",
      "Epoch 2 [54/54] - Loss: 0.7468745112419128  0.8426666666666667 Val Acc\n",
      "best model here\n",
      "0.8555 Test Accuracy\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 5)\n",
    "        self.fc1 = nn.Linear(4*4*32, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.pool(self.conv1(x)))\n",
    "        x = F.relu(self.pool(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Implement a train model function so you can re_use it in task 3 and 4. \n",
    "# Should return the best performing model after training\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs, msg, pretrained):\n",
    "    best_accuracy = 0\n",
    "    writer = SummaryWriter()\n",
    "    for epochs in range(num_epochs):\n",
    "        for batch_nr, (data, labels) in enumerate(train_loader):\n",
    "         \n",
    "            prediction = model.forward(data)\n",
    "\n",
    "            loss = criterion(prediction, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            writer.add_scalar(msg, loss, epochs)\n",
    "            print(\n",
    "            f'\\rEpoch {epochs+1} [{batch_nr+1}/{len(train_loader)}] - Loss: {loss}',\n",
    "            end=''\n",
    "        )\n",
    "        val_accuracy = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_nr, (data, labels) in enumerate(val_loader):\n",
    "                prediction = model.forward(data)\n",
    "                _, predicted = torch.max(prediction, 1)\n",
    "                val_accuracy += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "            print(\" \",val_accuracy/total, \"Val Acc\")\n",
    "            val_accuracy = val_accuracy/total\n",
    "            if(best_accuracy < val_accuracy and pretrained == False):\n",
    "                best_accuracy = val_accuracy\n",
    "                print(\"best model here\")\n",
    "                #torch.save(model.state_dict(), \"./E2\")\n",
    "def test_model(model, test_loader):\n",
    "    test_accuracy = 0\n",
    "    total = 0\n",
    "    predictList = []\n",
    "    testList = []\n",
    "    \n",
    "    for batch_nr, (data, labels) in enumerate(test_loader):\n",
    "        prediction = model.forward(data)\n",
    "        _, predicted = torch.max(prediction, 1)\n",
    "        for i in range(len(prediction)):\n",
    "            predictList.append(predicted[i].item())\n",
    "            testList.append(labels[i].item())\n",
    "        test_accuracy += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    print(test_accuracy/total, \"Test Accuracy\")\n",
    "  \n",
    "\n",
    "# Hyperparams. Set these to reasonable values\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# Load our network\n",
    "model = Net()\n",
    "\n",
    "# Define our loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define our optimizer\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), LEARNING_RATE)\n",
    "\n",
    "# Train the model\n",
    "msg = \"trainloss leaky relu and adam\"\n",
    "trained_model = train_model(model, criterion, optimizer, train_loader, val_loader, 2, msg, pretrained=False)\n",
    "\n",
    "# Test the model\n",
    "model.load_state_dict(torch.load(\"./E2\"))\n",
    "tested_model = test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./train_32x32.mat\n",
      "Using downloaded and verified file: ./test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.CenterCrop(28),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "data = torchvision.datasets.SVHN(\"./\", split = \"train\", download=True, transform= preprocess)\n",
    "test_data = torchvision.datasets.SVHN(\"./\", split= \"test\",download = True, transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9*len(data))\n",
    "test_size = len(data) - train_size\n",
    "train_set, val_set = torch.utils.data.random_split(data, [train_size,test_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size= BATCH_SIZE, shuffle= SHUFFLE )\n",
    "test_loader = DataLoader(test_data, batch_size= BATCH_SIZE, shuffle= SHUFFLE)\n",
    "val_loader = DataLoader(val_set, batch_size= BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16018746158574063 Test Accuracy\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.load_state_dict(torch.load(\"./E2\"))\n",
    "model.conv1 = nn.Sequential(\n",
    "    nn.Conv2d(3,1,1),\n",
    "    model.conv1\n",
    ")\n",
    "#trained_model = train_model(model, criterion, optimizer, train_loader, val_loader, 2, \"\", pretrained=True) \n",
    "tested_model = test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [66/66] - Loss: 2.2239487171173096  0.2022932022932023 Val Acc\n",
      "Epoch 2 [66/66] - Loss: 2.1577959060668945  0.22904722904722905 Val Acc\n",
      "0.23839889366933006 Test Accuracy\n"
     ]
    }
   ],
   "source": [
    "# Fine tuning\n",
    "model.load_state_dict(torch.load(\"./E2\"))\n",
    "model.conv1 = nn.Sequential(\n",
    "    nn.Conv2d(3,1,1),\n",
    "    model.conv1\n",
    ")\n",
    "model.last_linear = nn.Sequential(\n",
    "    nn.Linear(in_features=100, out_features=100),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(in_features=100, out_features=10),\n",
    ")\n",
    "trained_model = train_model(model, criterion, optimizer, train_loader, val_loader, 2, \"\", pretrained=True) \n",
    "tested_model = test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [66/66] - Loss: 3.1134521961212167  0.18004368004368004 Val Acc\n",
      "Epoch 2 [66/66] - Loss: 3.0234601497650146  0.18004368004368004 Val Acc\n",
      "0.16233866011063305 Test Accuracy\n"
     ]
    }
   ],
   "source": [
    "# Feature Extracting\n",
    "model.load_state_dict(torch.load(\"./E2\"))\n",
    "for params in model.parameters():\n",
    "    params.requires_grad = False\n",
    "\n",
    "model.conv1 = nn.Sequential(\n",
    "    nn.Conv2d(3,1,1),\n",
    "    model.conv1\n",
    ")\n",
    "model.last_linear = nn.Sequential(\n",
    "    nn.Linear(in_features=100, out_features=100),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(in_features=100, out_features=10),\n",
    ")\n",
    "trained_model = train_model(model, criterion, optimizer, train_loader, val_loader, 2, \"\", pretrained=True) \n",
    "tested_model = test_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

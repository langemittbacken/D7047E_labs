{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#    transforms.Resize(256),\n",
    "#    transforms.CenterCrop(224),\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "data = torchvision.datasets.CIFAR10(\"./\", train=True, download=True, transform=preprocess)\n",
    "test_data = torchvision.datasets.CIFAR10(\"./\", train=False, transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9*len(data))\n",
    "test_size = len(data) - train_size\n",
    "train_set, val_set = torch.utils.data.random_split(data, [train_size,test_size])\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=100,\n",
    "                                          shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=100,\n",
    "                                          shuffle=False)\n",
    "valloader = torch.utils.data.DataLoader(val_set, batch_size=100,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs, msg):\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for epochs in range(num_epochs):\n",
    "        for batch_nr, (data, labels) in enumerate(train_loader):\n",
    "         \n",
    "            prediction = model.forward(data)\n",
    "\n",
    "            loss = criterion(prediction, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            print(\n",
    "            f'\\rEpoch {epochs+1} [{batch_nr+1}/{len(train_loader)}] - Loss: {loss}',\n",
    "            end=''\n",
    "        )\n",
    "        val_accuracy = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_nr, (data, labels) in enumerate(val_loader):\n",
    "                prediction = model.forward(data)\n",
    "                _, predicted = torch.max(prediction, 1)\n",
    "                val_accuracy += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "            print(\" \",val_accuracy/total, \"Val Acc\")\n",
    "            val_accuracy = val_accuracy/total\n",
    "            if(best_accuracy < val_accuracy):\n",
    "                best_accuracy = val_accuracy\n",
    "                print(\"best model here\")\n",
    "                torch.save(model.state_dict(), \"./E1\")\n",
    "def test_model(model, test_loader):\n",
    "    test_accuracy = 0\n",
    "    total = 0\n",
    "    predictList = []\n",
    "    testList = []\n",
    "    \n",
    "    for batch_nr, (data, labels) in enumerate(test_loader):\n",
    "        prediction = model.forward(data)\n",
    "        _, predicted = torch.max(prediction, 1)\n",
    "        for i in range(len(prediction)):\n",
    "            predictList.append(predicted[i].item())\n",
    "            testList.append(labels[i].item())\n",
    "        test_accuracy += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    print(test_accuracy/total, \"Test Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [450/450] - Loss: 2.2975387573242188  0.1034 Val Acc\n",
      "best model here\n",
      "Epoch 2 [450/450] - Loss: 2.2819349765777593  0.118 Val Acc\n",
      "best model here\n",
      "Epoch 3 [450/450] - Loss: 2.2325534820556648  0.1422 Val Acc\n",
      "best model here\n",
      "Epoch 4 [450/450] - Loss: 2.2047097682952882  0.1908 Val Acc\n",
      "best model here\n",
      "Epoch 5 [450/450] - Loss: 2.2488265037536623  0.2298 Val Acc\n",
      "best model here\n",
      "Epoch 6 [450/450] - Loss: 2.1124379634857178  0.247 Val Acc\n",
      "best model here\n",
      "Epoch 7 [450/450] - Loss: 2.0964837074279785  0.2514 Val Acc\n",
      "best model here\n",
      "Epoch 8 [450/450] - Loss: 1.9765672683715825  0.2554 Val Acc\n",
      "best model here\n",
      "Epoch 9 [450/450] - Loss: 2.0073533058166504  0.2648 Val Acc\n",
      "best model here\n",
      "Epoch 10 [450/450] - Loss: 1.9896255731582642  0.2698 Val Acc\n",
      "best model here\n",
      "0.2913 Test Accuracy\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "LEARNING_RATE = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), LEARNING_RATE)\n",
    "msg = \"trainloss leaky and SGD\"\n",
    "trained_model = train_model(model, criterion, optimizer, trainloader, valloader, 10, msg)\n",
    "model.load_state_dict(torch.load(\"./E1\"))\n",
    "tested_model = test_model(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\odahl\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\odahl\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to C:\\Users\\odahl/.cache\\torch\\hub\\checkpoints\\alexnet-owt-7be5be79.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b6dc036a104078ba4a9e64c36e87c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/233M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [450/450] - Loss: 1.2906702756881714  0.5384 Val Acc\n",
      "best model here\n",
      "Epoch 2 [450/450] - Loss: 1.2389678955078125  0.5678 Val Acc\n",
      "best model here\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "model_ft = models.alexnet(pretrained=True)\n",
    "\n",
    "# Do the things required for fine-tuning before training the model\n",
    "model_ft.last_linear = nn.Sequential(\n",
    "    nn.Linear(in_features=100, out_features=10),\n",
    ")\n",
    "\n",
    "criterion_ft = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define our optimizer\n",
    "\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), LEARNING_RATE, weight_decay=1e-2)\n",
    "\n",
    "# Train the model\n",
    "trained_model_ft = train_model(model_ft, criterion_ft, optimizer_ft, trainloader, valloader, 2, \"1\")\n",
    "\n",
    "# Test the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5724 Test Accuracy\n"
     ]
    }
   ],
   "source": [
    "model_ft.load_state_dict(torch.load(\"./E1\"))\n",
    "tested_model = test_model(model_ft, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for first task, 0.5801 Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [450/450] - Loss: 0.9347338676452637  0.6324 Val Acc\n",
      "best model here\n",
      "Epoch 2 [450/450] - Loss: 1.0582861900329597  0.64 Val Acc\n",
      "best model here\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6128\\1529288009.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Test the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./E1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mtested_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "for params in model_ft.parameters():\n",
    "    params.requires_grad_ = False\n",
    "    \n",
    "criterion_fe = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define our optimizer\n",
    "\n",
    "optimizer_fe = optim.Adam(model_ft.parameters(), LEARNING_RATE, weight_decay=1e-2)\n",
    "\n",
    "# Train the model\n",
    "\n",
    "# Train the model\n",
    "trained_model_fe = train_model(model_ft, criterion_fe, optimizer_fe, trainloader, valloader, 2, \"\")\n",
    "\n",
    "# Test the model\n",
    "model_ft.load_state_dict(torch.load(\"./E1\"))\n",
    "tested_model = test_model(model_ft, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6392 Test Accuracy\n"
     ]
    }
   ],
   "source": [
    "tested_model = test_model(model_ft, testloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "02a2bbd04d22b0b729b0b7f054f479d5edfef8abe659c6664693311608c6e53e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

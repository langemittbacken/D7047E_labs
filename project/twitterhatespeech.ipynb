{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"id":"eOKO6JSLsI4T","outputId":"109a6063-3d97-4f3b-d7dc-5c62d107362f","execution":{"iopub.status.busy":"2023-05-22T07:43:13.795935Z","iopub.execute_input":"2023-05-22T07:43:13.796361Z","iopub.status.idle":"2023-05-22T07:43:28.619673Z","shell.execute_reply.started":"2023-05-22T07:43:13.796332Z","shell.execute_reply":"2023-05-22T07:43:28.618500Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.28.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.11.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.3.23)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\nimport numpy as np\nfrom matplotlib import pyplot\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.corpus import stopwords\nimport nltk\nfrom nltk import word_tokenize\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, classification_report\n \nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","metadata":{"id":"HQT5mXI5k7qq","execution":{"iopub.status.busy":"2023-05-22T07:43:28.625245Z","iopub.execute_input":"2023-05-22T07:43:28.625998Z","iopub.status.idle":"2023-05-22T07:43:32.517599Z","shell.execute_reply.started":"2023-05-22T07:43:28.625961Z","shell.execute_reply":"2023-05-22T07:43:32.516672Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"GhHRrykCbHqq","execution":{"iopub.status.busy":"2023-05-22T07:44:18.151855Z","iopub.execute_input":"2023-05-22T07:44:18.152471Z","iopub.status.idle":"2023-05-22T07:44:18.184445Z","shell.execute_reply.started":"2023-05-22T07:44:18.152434Z","shell.execute_reply":"2023-05-22T07:44:18.183335Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def preprocess_pandas(data, columns):\n    df_ = pd.DataFrame(columns=columns)\n    data['tweet'] = data['tweet'].str.lower()\n    data['tweet'] = data['tweet'].replace('[a-zA-Z0-9-_.]+@[a-zA-Z0-9-_.]+', '', regex=True)                      # remove emails\n    data['tweet'] = data['tweet'].replace('((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.|$)){4}', '', regex=True)    # remove IP address\n    data['tweet'] = data['tweet'].replace('@[a-zA-Z0-9-_]+', '@USER', regex=True)                                     # remove usernames\n    data['tweet'] = data['tweet'].replace('https:\\/\\/t\\.co\\/[a-zA-Z0-9]+', '', regex=True)                       # remove specific links\n    data['tweet'] = data['tweet'].str.replace('[^\\w\\s]','')                                                      # remove special characters\n    data['tweet'] = data['tweet'].replace('\\d', '', regex=True)          \n    data['tweet'] = '[CLS] ' + data['tweet'] + ' [SEP]'                    \n# remove numbers\n    for index, row in data.iterrows():\n        #filtered_sent = [w for w in word_tokens if not w in stopwords.words('english')]\n        df_ = df_.append({\n            \"index\": row['id'],\n            \"class\": row['subtask_a'],\n            \"tweet\": row['tweet']\n        }, ignore_index=True)\n    return data","metadata":{"id":"Ftz3vZ4P97RP","execution":{"iopub.status.busy":"2023-05-22T07:47:47.875951Z","iopub.execute_input":"2023-05-22T07:47:47.876342Z","iopub.status.idle":"2023-05-22T07:47:47.885136Z","shell.execute_reply.started":"2023-05-22T07:47:47.876305Z","shell.execute_reply":"2023-05-22T07:47:47.884190Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\n# If this is the primary file that is executed (ie not an import of another file)\nif __name__ == \"__main__\":\n    # get data, pre-process and split\n    data = pd.read_csv(\"/kaggle/input/hasoc-2019/english_dataset.tsv\", delimiter='\\t', header=None)\n    data.columns = ['id','tweet', 'task_1', 'task_2', 'task_3']\n    data['index'] = data.index                                          # add new column index\n    columns = ['id', 'task_2', 'tweet']\n    data = preprocess_pandas(data, columns)        # pre-process\n    data = data.drop(0)                     \n    training_data, validation_data, training_labels, validation_labels = train_test_split( # split the data into training, validation, and test splits\n        data['tweet'].values.astype('U'),\n        data['task_2'].values.astype('U'),\n        test_size=0.10,\n        random_state=0,\n        shuffle=True\n    )\n    test_data = pd.read_csv(\"/kaggle/input/hasoc-2019/hasoc2019_en_test-2919.tsv\", delimiter = '\\t', header = None)\n    test_data.columns = ['id', 'tweet', 'task_1', 'task_2', 'task_3']\n    test_data['index'] = test_data.index\n    test_data = preprocess_pandas(test_data, columns)\n    test_data = test_data.drop(0)\n\n    \n\n\n","metadata":{"id":"2VK_aENEogDw","execution":{"iopub.status.busy":"2023-05-18T21:16:06.147583Z","iopub.execute_input":"2023-05-18T21:16:06.148005Z","iopub.status.idle":"2023-05-18T21:17:26.321813Z","shell.execute_reply.started":"2023-05-18T21:16:06.147973Z","shell.execute_reply":"2023-05-18T21:17:26.320654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"olid_data = pd.read_csv(\"/kaggle/input/olid-data/OLID_Tain_ATUSER_URL_EmojiRemoved_Pedro.txt\", delimiter = '\\t', header = None)\nolid_data.columns = ['id', 'tweet', 'subtask_a', 'subtask_b', 'subtask_c']\nolid_data['index'] = olid_data.index\ncolumns = ['id', 'tweet', 'subtask_a']\nolid_data = preprocess_pandas(olid_data, columns)\nolid_data = olid_data.drop(0)\n\nolid_data = olid_data.fillna('NONE')\n\ntrain_data, test_data, train_labels, test_labels = train_test_split( # split the data into training, validation, and test splits\n    olid_data['tweet'].values.astype('U'),\n    olid_data['subtask_a'].values.astype('U'),\n    test_size=0.10,\n    random_state=0,\n    shuffle=True\n    )","metadata":{"id":"g60p8Y93nmE7","execution":{"iopub.status.busy":"2023-05-22T07:48:38.071843Z","iopub.execute_input":"2023-05-22T07:48:38.072211Z","iopub.status.idle":"2023-05-22T07:54:42.544884Z","shell.execute_reply.started":"2023-05-22T07:48:38.072179Z","shell.execute_reply":"2023-05-22T07:54:42.543953Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(data['task_2'].value_counts())\nprint(test_data['task_2'].value_counts())","metadata":{"id":"Synsas0G_nf4","outputId":"e9dd63fd-ef1e-41ac-9c99-3b474693136e","execution":{"iopub.status.busy":"2023-05-18T21:17:26.349436Z","iopub.execute_input":"2023-05-18T21:17:26.350166Z","iopub.status.idle":"2023-05-18T21:17:26.376715Z","shell.execute_reply.started":"2023-05-18T21:17:26.350127Z","shell.execute_reply":"2023-05-18T21:17:26.375489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer\nbertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n\ntokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")","metadata":{"id":"_uLft9gPyyKg","outputId":"b651b22e-8b03-4479-9d91-bf0bc9a172b8","execution":{"iopub.status.busy":"2023-05-22T07:55:22.761292Z","iopub.execute_input":"2023-05-22T07:55:22.761640Z","iopub.status.idle":"2023-05-22T07:55:37.484825Z","shell.execute_reply.started":"2023-05-22T07:55:22.761612Z","shell.execute_reply":"2023-05-22T07:55:37.483734Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/558 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2aaeee2175ed4ee0961b6e84e837485e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c847a560b20b4b1c97a127bddf679104"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad8a1c90972241169b91352744648998"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b58f65809f04367a13e4a6c9b889688"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Conv1D, GlobalMaxPooling1D, Dense\nfrom keras.utils import to_categorical\nfrom torch.nn.utils.rnn import pad_sequence\n\nlabels_map = {\n    \"NONE\" : 0,\n    \"HATE\" : 1,\n    \"PRFN\" : 2,\n    \"OFFN\" : 3\n}\n\nolid_labels_map = {\n    \"NONE\" : 0,\n    \"UNT\" : 1,\n    \"TIN\" : 2\n}\nolid_labels_map2 = {\n    \"OFF\" : 0,\n    \"NOT\" : 1\n}\n\nbertweet = bertweet.to(device)\nword_embeddings = []\ntest_embeddings = []\nlabels = []\ntest_labels = []","metadata":{"id":"3u8-Km0ZIFyT","execution":{"iopub.status.busy":"2023-05-22T07:55:37.486674Z","iopub.execute_input":"2023-05-22T07:55:37.490461Z","iopub.status.idle":"2023-05-22T07:55:42.064611Z","shell.execute_reply.started":"2023-05-22T07:55:37.490428Z","shell.execute_reply":"2023-05-22T07:55:42.063452Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\n\n#OLID\nfor n in olid_data.iloc():\n    input_ids = torch.tensor([tokenizer.encode(n[\"tweet\"])]).to(device)\n    with torch.no_grad():\n      if(input_ids.shape[1] < 128):\n        features = bertweet(input_ids)  # Models outputs are now tuples\n        cls_features = features[-1][0,:].cpu()  # Take the [CLS] features and move to CPU\n        word_embeddings.append(cls_features)\n        labels.append(olid_labels_map2[n['subtask_a']])\n\n\n\n","metadata":{"id":"it_uuY5y44pr","execution":{"iopub.status.busy":"2023-05-22T08:00:18.810073Z","iopub.execute_input":"2023-05-22T08:00:18.810460Z","iopub.status.idle":"2023-05-22T08:02:22.589412Z","shell.execute_reply.started":"2023-05-22T08:00:18.810430Z","shell.execute_reply":"2023-05-22T08:02:22.588427Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#HASOC\nfor n in data.iloc():\n    input_ids = torch.tensor([tokenizer.encode(n[\"tweet\"])]).to(device)\n    with torch.no_grad():\n      if(input_ids.shape[1] < 128):\n        features = bertweet(input_ids)  # Models outputs are now tuples\n        cls_features = features[-1][0,:].cpu()  # Take the [CLS] features and move to CPU\n        word_embeddings.append(cls_features)\n        labels.append(labels_map[n['task_2']])\n\nfor n in test_data.iloc():\n    input_ids = torch.tensor([tokenizer.encode(n[\"tweet\"])]).to(device)\n    with torch.no_grad():\n      if(input_ids.shape[1] < 128):\n        features = bertweet(input_ids)  # Models outputs are now tuples\n        cls_features = features[-1][0,:].cpu()  # Take the [CLS] features and move to CPU\n        test_embeddings.append(cls_features)\n        test_labels.append(labels_map[n['task_2']])","metadata":{"id":"mehJ3r7gGDp5","execution":{"iopub.status.busy":"2023-05-18T21:29:09.262334Z","iopub.execute_input":"2023-05-18T21:29:09.262812Z","iopub.status.idle":"2023-05-18T21:30:18.094950Z","shell.execute_reply.started":"2023-05-18T21:29:09.262773Z","shell.execute_reply":"2023-05-18T21:30:18.093981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(word_embeddings[2])","metadata":{"id":"MgQDkdsnWrn9","outputId":"37bf84f8-16e7-4e3e-b819-49514cbbe6e7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to Torch tensors\nimport torch\nimport torch.nn.functional as F\n\n#print(word_embeddings.shape)\n#word_embeddings = F.pad(word_embeddings, pad=(0, 0, 0, 100 - word_embeddings.shape[1]))\n\nfrom torch.nn.utils.rnn import pad_sequence\n\n\nX = torch.stack(word_embeddings)\n#X_test = torch.stack(test_embeddings)\ny = torch.tensor(labels)\n#y_test = torch.tensor(test_labels)\n\ndataset = TensorDataset(X, y)\n#testData = TensorDataset(X_test, y_test)\n\ntrain_size = int(0.85 * len(dataset))\nval_size = int(0.05 * len(dataset))\ntest_size = int(0.1 * len(dataset)) \n\ntrain_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(12392))\n# Creating dataloader\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size = 64, shuffle = True)\n\n# Assuming the shape of an individual embedding is (sequence_length, embedding_dim)\n\n# Number of classes\nnum_classes = len(labels_map)\n","metadata":{"id":"Kz2DFzDYNthM","execution":{"iopub.status.busy":"2023-05-22T08:04:47.682200Z","iopub.execute_input":"2023-05-22T08:04:47.682590Z","iopub.status.idle":"2023-05-22T08:04:47.774441Z","shell.execute_reply.started":"2023-05-22T08:04:47.682557Z","shell.execute_reply":"2023-05-22T08:04:47.773485Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from torch.autograd import Variable \nfrom sklearn.metrics import f1_score\nfrom torch.optim.lr_scheduler import StepLR\n\nclass CNN(nn.Module):\n    def __init__(self, embedding_dim, num_classes, hidden_size, num_layers):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv1d(embedding_dim, 668, kernel_size=1, stride=1)\n        self.conv2 = nn.Conv1d(668,568,1)\n        self.fc1 = nn.Linear(256, 128)\n        self.fc2 = nn.Linear(128, num_classes)\n        self.dropout = nn.Dropout(0.5)\n        self.bn2 = nn.BatchNorm1d(360)\n        self.lstm = nn.LSTM(568, hidden_size, num_layers, batch_first=True, bidirectional = True) # LSTM layer\n        self.fc_1 =  nn.Linear(2*hidden_size, hidden_size) #fFirst FC layer\n        self.fc = nn.Linear(hidden_size, num_classes) # Final FC layer\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool1d(x, x.size(2))\n        x = self.dropout(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.max_pool1d(x,x.size(2)).squeeze(2)\n        x = self.dropout(x)\n        x = F.relu(self.fc1(x))\n        X = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n    def forward2(self, x):\n        x = x.unsqueeze(2)  # Add an extra dimension for the Conv1D\n        x = torch.permute(x, (0,2,1))\n        # Pass x (not x_conv) through LSTM because LSTM expects a sequence\n        h_0 = Variable(torch.zeros(4, x.size(0), 400)).to(device) #hidden state\n        c_0 = Variable(torch.zeros(4, x.size(0), 400)).to(device) #internal state\n\n\n        # Propagate input through LSTM\n        out, _ = self.lstm(x, (h_0, c_0)) # LSTM with input, hidden, and internal state\n        out = out[:, -1, :] # Take the last output for classification\n        out = F.relu(out)\n        out = self.fc_1(out) #first Dense\n        out = F.relu(out) #relu\n        out = self.fc(out) #Final Output\n        return out\n    def forward3(self, x):\n        x = x.unsqueeze(2)\n  \n        x = F.relu(self.conv1(x))\n        x = F.max_pool1d(x, x.size(2))\n        #x = self.dropout(x)\n        x = F.relu((self.conv2(x)))\n        x = F.max_pool1d(x,x.size(2))\n        #x = self.dropout(x)\n        x = x.transpose(1,2)\n\n        h_0 = Variable(torch.zeros(4, x.size(0), 400)).to(device) #hidden state\n        c_0 = Variable(torch.zeros(4, x.size(0), 400)).to(device) #internal state\n       \n        # Propagate input through LSTM\n        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n        #hn = hn.view(-1, 400) #reshaping the data for Dense layer next\n        hn = torch.cat((hn[-2,:,:], hn[-1,:,:]), dim=1)\n        out = F.relu(hn)\n        out = self.fc_1(out) #first Dense\n        out = F.relu(out) #relu\n        out = self.dropout(out)\n        out = self.fc(out) #Final Output\n        return out\n\nclass EarlyStopping:\n    def __init__(self, patience=7, verbose=False, delta=0):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement. \n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        '''Saves model when validation loss decrease.'''\n        if self.verbose:\n            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), 'checkpoint.pt')\n        self.val_loss_min = val_loss\n\n  \n\ndef train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs, scheduler, early_stopping):\n    train_accuracy = 0\n    total = 0\n    val_loss_history = []\n\n    for epochs in range(num_epochs):\n        model.train()\n        for batch_nr, (data, labels) in enumerate(train_loader):\n            data = data.to(device)\n            labels = labels.to(device)\n\n            prediction = model.forward3(data)\n            loss = criterion(prediction, labels)\n\n            loss.backward()\n\n            optimizer.step()\n\n            optimizer.zero_grad()\n            \n            _, predicted = torch.max(prediction, 1)\n            train_accuracy += (predicted == labels).sum().item()\n            total += labels.size(0)\n            \n        # Call scheduler.step() after each epoch, not each batch\n        scheduler.step()\n\n        val_acc = 0 \n        val_total = 0\n        val_loss_epoch = 0\n        with torch.no_grad():\n            for batch_nr, (data, labels) in enumerate(val_loader):\n                data = data.to(device)\n                labels = labels.to(device)\n                prediction = model.forward3(data).to(device)\n\n                val_loss = criterion(prediction, labels)\n\n                val_loss_epoch += val_loss.item() # Keep track of the total loss for this epoch\n                _, predicted = torch.max(prediction, 1)\n                val_acc += (predicted == labels).sum().item()\n                val_total += labels.size(0)\n\n            val_loss_epoch = val_loss_epoch / len(val_loader) # Get the average loss for this epoch\n            val_loss_history.append(val_loss_epoch) # Add to the history\n            \n            print(\n                f'\\rEpoch {epochs+1} [{batch_nr+1}/{len(train_loader)}] - Loss: {loss} - ValLoss: {val_loss_epoch}  - ValAcc: {val_acc/val_total}',\n                end='')\n\n            # Here we call early stopping\n            early_stopping(val_loss_epoch, model)\n            if early_stopping.early_stop:\n                print(\"Early stopping\")\n                break\n\n    return val_loss_history\n\n\n \ndef test_model(model, test_loader):\n    # Set the model to evaluation mode\n  correct = 0\n  total = 0\n  predlist = []\n  truelist = []\n  with torch.no_grad():  # No need to track gradients\n    model.eval()\n    for data, labels in test_loader:\n      data = data.to(device)\n      labels = labels.to(device)\n      outputs = model.forward3(data)\n      _, predicted = torch.max(outputs, 1)\n      total += labels.size(0)\n      correct += (predicted == labels).sum().item()\n      #f1 = f1_score(predicted, labels, average = 'weighted')\n      for i in range(len(predicted)):\n        predlist.append(predicted[i].item())\n        truelist.append(labels[i].item())\n\n  print('Test Accuracy of the model on the test set: {} %'.format(100 * correct / total))\n  #print('F1-score', f1)\n  return truelist, predlist\n\n\n","metadata":{"id":"2sfRX0fNKkiY","execution":{"iopub.status.busy":"2023-05-22T08:15:37.732318Z","iopub.execute_input":"2023-05-22T08:15:37.732707Z","iopub.status.idle":"2023-05-22T08:15:37.769087Z","shell.execute_reply.started":"2023-05-22T08:15:37.732676Z","shell.execute_reply":"2023-05-22T08:15:37.768134Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model = CNN(768, 2, 400, 2)\nmodel = torch.compile(model)\nmodel = model.to(device)\nepochs = 50\nLEARNING_RATE = 1e-3\n# Define our loss function\nweights = [1,1]\nclass_weights = torch.FloatTensor(weights).to(device)\ncriterion = nn.CrossEntropyLoss(weight = class_weights)\n\n# Define our optimizer\n\noptimizer = optim.Adam(model.parameters(), LEARNING_RATE)\nscheduler = StepLR(optimizer, step_size=30, gamma=0.1)\nearly_stopping = EarlyStopping(patience = 10, verbose = True)\n# Train the model\ntrained_model = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs = epochs, scheduler = scheduler, early_stopping = early_stopping)\ntruelist, predlist = test_model(model, test_loader)","metadata":{"id":"K0k2WaqgL6Xp","outputId":"09479e26-9cc6-462e-8296-1d6bd7c96020","execution":{"iopub.status.busy":"2023-05-22T08:15:45.156961Z","iopub.execute_input":"2023-05-22T08:15:45.157347Z","iopub.status.idle":"2023-05-22T08:17:30.500784Z","shell.execute_reply.started":"2023-05-22T08:15:45.157311Z","shell.execute_reply":"2023-05-22T08:17:30.499789Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Epoch 1 [21/352] - Loss: 0.5147656798362732 - ValLoss: 0.5925736242816562  - ValAcc: 0.6910876132930514Validation loss decreased (inf --> 0.592574).  Saving model ...\nEpoch 2 [21/352] - Loss: 0.5242037177085876 - ValLoss: 0.5507185998417082  - ValAcc: 0.7424471299093656Validation loss decreased (0.592574 --> 0.550719).  Saving model ...\nEpoch 3 [21/352] - Loss: 0.4253119230270386 - ValLoss: 0.5548610744022188  - ValAcc: 0.7265861027190332EarlyStopping counter: 1 out of 10\nEpoch 4 [21/352] - Loss: 0.6118273138999939 - ValLoss: 0.5372001230716705  - ValAcc: 0.736404833836858Validation loss decreased (0.550719 --> 0.537200).  Saving model ...\nEpoch 5 [21/352] - Loss: 0.6221610903739929 - ValLoss: 0.5282823954309736  - ValAcc: 0.7424471299093656Validation loss decreased (0.537200 --> 0.528282).  Saving model ...\nEpoch 6 [21/352] - Loss: 0.4531584680080414 - ValLoss: 0.6435825668630146  - ValAcc: 0.7190332326283988EarlyStopping counter: 1 out of 10\nEpoch 7 [21/352] - Loss: 0.5714075565338135 - ValLoss: 0.5285346919582004  - ValAcc: 0.7530211480362538EarlyStopping counter: 2 out of 10\nEpoch 8 [21/352] - Loss: 0.6118974089622498 - ValLoss: 0.5721098567758288  - ValAcc: 0.7122356495468278EarlyStopping counter: 3 out of 10\nEpoch 9 [21/352] - Loss: 0.48131483793258667 - ValLoss: 0.5253146631377084  - ValAcc: 0.7341389728096677Validation loss decreased (0.528282 --> 0.525315).  Saving model ...\nEpoch 10 [21/352] - Loss: 0.48768970370292664 - ValLoss: 0.5067292948563894  - ValAcc: 0.756797583081571Validation loss decreased (0.525315 --> 0.506729).  Saving model ...\nEpoch 11 [21/352] - Loss: 0.6102214455604553 - ValLoss: 0.5872374843983423  - ValAcc: 0.6699395770392749EarlyStopping counter: 1 out of 10\nEpoch 12 [21/352] - Loss: 0.5271682143211365 - ValLoss: 0.5259091953436533  - ValAcc: 0.75EarlyStopping counter: 2 out of 10\nEpoch 13 [21/352] - Loss: 0.5971682667732239 - ValLoss: 0.5207266466958183  - ValAcc: 0.7552870090634441EarlyStopping counter: 3 out of 10\nEpoch 14 [21/352] - Loss: 0.5277953743934631 - ValLoss: 0.5195964163257962  - ValAcc: 0.743202416918429EarlyStopping counter: 4 out of 10\nEpoch 15 [21/352] - Loss: 0.458066463470459 - ValLoss: 0.5101679364840189  - ValAcc: 0.7560422960725075EarlyStopping counter: 5 out of 10\nEpoch 16 [21/352] - Loss: 0.3772432506084442 - ValLoss: 0.5057525038719177  - ValAcc: 0.7598187311178247Validation loss decreased (0.506729 --> 0.505753).  Saving model ...\nEpoch 17 [21/352] - Loss: 0.4040929675102234 - ValLoss: 0.5026760768322718  - ValAcc: 0.7628398791540786Validation loss decreased (0.505753 --> 0.502676).  Saving model ...\nEpoch 18 [21/352] - Loss: 0.43767598271369934 - ValLoss: 0.4996028883116586  - ValAcc: 0.7590634441087614Validation loss decreased (0.502676 --> 0.499603).  Saving model ...\nEpoch 19 [21/352] - Loss: 0.42051753401756287 - ValLoss: 0.5431457999206725  - ValAcc: 0.7409365558912386EarlyStopping counter: 1 out of 10\nEpoch 20 [21/352] - Loss: 0.5157983899116516 - ValLoss: 0.503489077091217  - ValAcc: 0.7590634441087614EarlyStopping counter: 2 out of 10\nEpoch 21 [21/352] - Loss: 0.4725784361362457 - ValLoss: 0.5081796177795955  - ValAcc: 0.7643504531722054EarlyStopping counter: 3 out of 10\nEpoch 22 [21/352] - Loss: 0.5438819527626038 - ValLoss: 0.5106976443812961  - ValAcc: 0.7620845921450151EarlyStopping counter: 4 out of 10\nEpoch 23 [21/352] - Loss: 0.3861735463142395 - ValLoss: 0.5201159829185122  - ValAcc: 0.7477341389728097EarlyStopping counter: 5 out of 10\nEpoch 24 [21/352] - Loss: 0.36199018359184265 - ValLoss: 0.5386937913440523  - ValAcc: 0.7318731117824774EarlyStopping counter: 6 out of 10\nEpoch 25 [21/352] - Loss: 0.3100106120109558 - ValLoss: 0.5136536246254331  - ValAcc: 0.7416918429003021EarlyStopping counter: 7 out of 10\nEpoch 26 [21/352] - Loss: 0.42975664138793945 - ValLoss: 0.48869899482954116  - ValAcc: 0.7583081570996979Validation loss decreased (0.499603 --> 0.488699).  Saving model ...\nEpoch 27 [21/352] - Loss: 0.543999433517456 - ValLoss: 0.4901478091875712  - ValAcc: 0.7537764350453172EarlyStopping counter: 1 out of 10\nEpoch 28 [21/352] - Loss: 0.46025800704956055 - ValLoss: 0.49549157988457454  - ValAcc: 0.7590634441087614EarlyStopping counter: 2 out of 10\nEpoch 29 [21/352] - Loss: 0.46700382232666016 - ValLoss: 0.5016405397937411  - ValAcc: 0.7673716012084593EarlyStopping counter: 3 out of 10\nEpoch 30 [21/352] - Loss: 0.6636922359466553 - ValLoss: 0.5691441425255367  - ValAcc: 0.7477341389728097EarlyStopping counter: 4 out of 10\nEpoch 31 [21/352] - Loss: 0.2571134865283966 - ValLoss: 0.49788573526200797  - ValAcc: 0.770392749244713EarlyStopping counter: 5 out of 10\nEpoch 32 [21/352] - Loss: 0.28744205832481384 - ValLoss: 0.4867217668465206  - ValAcc: 0.7779456193353474Validation loss decreased (0.488699 --> 0.486722).  Saving model ...\nEpoch 33 [21/352] - Loss: 0.35214582085609436 - ValLoss: 0.48989442984263104  - ValAcc: 0.7666163141993958EarlyStopping counter: 1 out of 10\nEpoch 34 [21/352] - Loss: 0.28509482741355896 - ValLoss: 0.49406079876990544  - ValAcc: 0.7681268882175226EarlyStopping counter: 2 out of 10\nEpoch 35 [21/352] - Loss: 0.2914900779724121 - ValLoss: 0.484566582100732  - ValAcc: 0.7764350453172205Validation loss decreased (0.486722 --> 0.484567).  Saving model ...\nEpoch 36 [21/352] - Loss: 0.27027514576911926 - ValLoss: 0.49637040212040856  - ValAcc: 0.7749244712990937EarlyStopping counter: 1 out of 10\nEpoch 37 [21/352] - Loss: 0.3197419345378876 - ValLoss: 0.49920999719983056  - ValAcc: 0.7749244712990937EarlyStopping counter: 2 out of 10\nEpoch 38 [21/352] - Loss: 0.33018243312835693 - ValLoss: 0.488999951453436  - ValAcc: 0.775679758308157EarlyStopping counter: 3 out of 10\nEpoch 39 [21/352] - Loss: 0.3308231234550476 - ValLoss: 0.5047277623698825  - ValAcc: 0.7734138972809668EarlyStopping counter: 4 out of 10\nEpoch 40 [21/352] - Loss: 0.5108490586280823 - ValLoss: 0.5008770383539654  - ValAcc: 0.7749244712990937EarlyStopping counter: 5 out of 10\nEpoch 41 [21/352] - Loss: 0.2802409827709198 - ValLoss: 0.49093150950613473  - ValAcc: 0.7809667673716012EarlyStopping counter: 6 out of 10\nEpoch 42 [21/352] - Loss: 0.3439081609249115 - ValLoss: 0.4806532306330545  - ValAcc: 0.7802114803625377Validation loss decreased (0.484567 --> 0.480653).  Saving model ...\nEpoch 43 [21/352] - Loss: 0.37475863099098206 - ValLoss: 0.49843340686389376  - ValAcc: 0.7719033232628398EarlyStopping counter: 1 out of 10\nEpoch 44 [21/352] - Loss: 0.33559033274650574 - ValLoss: 0.48451908003716243  - ValAcc: 0.7877643504531722EarlyStopping counter: 2 out of 10\nEpoch 45 [21/352] - Loss: 0.37994396686553955 - ValLoss: 0.4911626818634215  - ValAcc: 0.7802114803625377EarlyStopping counter: 3 out of 10\nEpoch 46 [21/352] - Loss: 0.3452734053134918 - ValLoss: 0.4967837319487617  - ValAcc: 0.7779456193353474EarlyStopping counter: 4 out of 10\nEpoch 47 [21/352] - Loss: 0.3151318430900574 - ValLoss: 0.49442229952131  - ValAcc: 0.7809667673716012EarlyStopping counter: 5 out of 10\nEpoch 48 [21/352] - Loss: 0.4551355540752411 - ValLoss: 0.4866949206306821  - ValAcc: 0.7794561933534743EarlyStopping counter: 6 out of 10\nEpoch 49 [21/352] - Loss: 0.366996169090271 - ValLoss: 0.4943449880395617  - ValAcc: 0.7764350453172205EarlyStopping counter: 7 out of 10\nEpoch 50 [21/352] - Loss: 0.43368178606033325 - ValLoss: 0.4863817180906023  - ValAcc: 0.7832326283987915EarlyStopping counter: 8 out of 10\nTest Accuracy of the model on the test set: 78.02114803625378 %\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load('checkpoint.pt'))\ntruelist, predlist = test_model(model, test_loader)","metadata":{"id":"KCIXoORXxffz","outputId":"56baa19f-fecb-4ed6-aebc-f9f39a5b6dff","execution":{"iopub.status.busy":"2023-05-22T08:18:49.192688Z","iopub.execute_input":"2023-05-22T08:18:49.193068Z","iopub.status.idle":"2023-05-22T08:18:49.381008Z","shell.execute_reply.started":"2023-05-22T08:18:49.193036Z","shell.execute_reply":"2023-05-22T08:18:49.380025Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Test Accuracy of the model on the test set: 78.20996978851964 %\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    import itertools\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    \n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","metadata":{"id":"SlCrhWGrQZRp","execution":{"iopub.status.busy":"2023-05-22T08:07:25.782178Z","iopub.execute_input":"2023-05-22T08:07:25.782777Z","iopub.status.idle":"2023-05-22T08:07:25.794012Z","shell.execute_reply.started":"2023-05-22T08:07:25.782739Z","shell.execute_reply":"2023-05-22T08:07:25.792809Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"\n    cnf_matrix = confusion_matrix(truelist, predlist)\n    np.set_printoptions(precision=2)\n    plt.figure()\n    plot_confusion_matrix(cnf_matrix, classes=['OFF', 'NONE'])","metadata":{"id":"NTZt55HbMdUb","outputId":"05737d82-8d44-45bc-f4e5-5aaa99f9edce","execution":{"iopub.status.busy":"2023-05-22T08:18:56.336497Z","iopub.execute_input":"2023-05-22T08:18:56.336860Z","iopub.status.idle":"2023-05-22T08:18:56.575949Z","shell.execute_reply.started":"2023-05-22T08:18:56.336828Z","shell.execute_reply":"2023-05-22T08:18:56.574838Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Confusion matrix, without normalization\n[[ 516  347]\n [ 230 1555]]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"def plot_val_loss(val_loss_history):\n    plt.plot(val_loss_history)\n    plt.title('Model validation loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.show()\n\n# Plot validation loss\nplot_val_loss(trained_model)","metadata":{"id":"Ui4mVsMRrz0L","outputId":"3b3a5e66-4e87-42ff-8335-026325b24f76","execution":{"iopub.status.busy":"2023-05-18T22:28:33.804922Z","iopub.execute_input":"2023-05-18T22:28:33.805309Z","iopub.status.idle":"2023-05-18T22:28:34.020299Z","shell.execute_reply.started":"2023-05-18T22:28:33.805277Z","shell.execute_reply":"2023-05-18T22:28:34.019436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}